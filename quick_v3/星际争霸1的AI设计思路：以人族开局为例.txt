星际争霸1的AI设计思路：以人族开局为例

现在看来，伯克利分校的星际争霸1AI―― “主宰”充其量是个微操机器人。它一如既往地没有认识到，AI能够“随机应变”这个问题的解决，最终的答案就是问题本身――随机地应变。

星际争霸1是一款即时策略类游戏。我们就从策略入手，以人族的开局为例说明如何设计真正的AI。电脑AI选定人族后如何发展自己呢？不妨将它视为一连串策略的发生、执行与完成，这一切又都由AI自己随机决定。为何要随机的理由很充分，任何一种无论多么成功的策略体系出现一次后都会被针对，一旦如此，AI就不再是AI了，人们发现那变成了愚蠢的行为。相反，有时看似愚蠢的行为，随着事情的发展却变得很聪明。

1、主动型策略
（1）采矿；
（2）建造：
放BS；
放BB；
放BR；
放BC。
（3）训练（比如，造SCV）；
（4）探路；
（5）攻击；
（6）野BB。

2、被动型策略
（1）穿矿聚团攻击；
（2）散点围攻。

3、偶发型策略
（1）野BS；
（2）封气矿。

这些策略属于基本策略，是不完整的，你还可以将其归为两类供选择。不管怎样，我们将它们的集合统称为策略集。重要的是还有一类：

4、优化型策略
（1）先定分析
如同一名人类选手新学星际这个游戏，AI需要对地图、兵种等进行基本的分析，依据有关数据确定每个时段的必须完成的任务、基本的发展路线。
能做到这一点是因为，星际的资源、兵力和科技在一定时间内是有上限的。

（2）指令序列
指令序列必须具备策略集（供选择策略）、计算和比对功能。进入游戏后，AI为每个SCV建立一个指令序列（相当于一个独立的电脑进程或应用程序），
来控制SCV。假如随机取到采矿这个策略，那么，四个SCV可以同时去距自己最近的水晶采矿。与之同时，为大本建立起的指令序列训练一个SCV。
假如电脑在拥有9个SCV时选到探路策略，那么就随机选一个SCV，计算出一条路线，出去探路。假如这个SCV在探到对方后遭遇攻击，指令序列根据先定
分析中的数据比对攻击与防御，决定攻击还是躲避。假如这个SCV不幸地遭遇散点围攻（类似于6条小狗合围）后阵亡，则该指令序列删除。

（3）策略中心
控制线。对（1）的问题做出回应的就是它。在游戏进行到某个时间，依据自身采集的资源情况、侦查情况，修正或继续执行原来的策略。
例如，当水晶达到100时，大本返回（或控制线直接读取到）这个信息，控制线从自身的策略集中选择策略，决定是放BS，或是等待，继续训练SCV，满150水晶时放BB。
这些信息返回给大本。水晶达到150时，控制线随机选一个SCV放BB。当探路的SCV探完对方后，返回信息给控制线表示任务完成，控制线决定这个SCV的下一步动作，
比如，此时对方探路农民同样到达了AI家中，AI家中尚未造建筑，则控制线有可能选到野BS或野BB。理由是，从人类选手的操作可以知道，一个要放建筑的农民可能
很长时间都放不下。所以，指令序列给出的任务应当是有时间属性的，超过某个时点则交由控制线处理，这同样可以用来对付对方的封气矿策略。控制线还应当有个
某个时段占据某个有利地形，或某些兵种前往某地的策略，等等。它决定了兵力部署、站位。
交叉策略中心。SCV遭遇对方探路农民的骚扰性攻击后，可能选择攻击策略（穿矿聚团攻击或散点围攻），这需要多个指令序列的协同，因此可以选择创建一个新的指令序列
来进行控制。我们将它称为一个交叉策略中心。

（4）分析中心
先定分析属于这部分的内容。只是它如此重要，以致将它提前了。分析中心又应当具备更多的功能。
学习。也就是对AI自身的整体性训练，包括自我对战训练、与其他选手的对战训练和调整策略集、控制线等。策略集一开始是不完整的，但可以通过与一个同自身一样的
程序来对战，扩充和优化策略集。分析中心通过对对战录像的分析（当然只能是代码形式的），读取有关数据，切分各时段资源、兵力和科技等情况，选取较优的部分纳入策略集，删除不合理的策略。如有必要，为策略赋予时间属性。这样，就可能出现一个AI学习到的大招。其他也是如此。

基于随机性的电脑AI不会每次都胜，因为世界是公平的。但是，随着电脑AI的强大，完全可以预言，星际争霸1的平衡性将被彻底打破。公平将不再是对一个人类选手和一个电脑AI而言，而只是对一个AI与另一个AI而言。我们需要的将是1024线，看到的将是真正的不夜城。3个枪兵旋转打地刺不是奇迹，也许，我们打开AI间的对战一看，一个AI正在甩枪兵。

